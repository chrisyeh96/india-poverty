attr(screening[[s]], "label")
})
var.descriptions <- as.data.frame((names(screening)))
var.descriptions <- as.data.frame(fn(names(screening)))
var.descriptions <- as.data.frame(fn(names(screening)))
var.descriptoins
var.descriptions
var.descriptions <- as.data.frame(tmp_fn(names(screening)))
tmp_fn = Vectorize(function(s) {
attr(screening[[s]], "label")
})
var.descriptions <- as.data.frame(tmp_fn(names(screening)))
colnames(var.descriptions) <- c("Description")
kable(var.descriptions, format="markdown")
print(mean(drug_class_not_found, na.rm=T))
for (i in 1:(nrow(screening))) {
drug_classes[[i]] <- list()
}
drug_class_not_found <- matrix(as.logical(rep(NA, 10*nrow(screening))), ncol=10)
for (i in 1:(nrow(screening))) {
drug_classes[[i]] <- list()
}
drug_var <- c("SRRXDA1", "SRRXDB1", "SRRXDC1", "SRRXDD1", "SRRXDE1", "SRRXDF1", "SRRXDG1", "SRRXDH1", "SRRXDI1", "SRRXDJ1")
drug_class_not_found <- matrix(as.logical(rep(NA, 10*nrow(screening))), ncol=10)
for (i in 1:(nrow(screening))) {
drug_classes[[i]] <- list()
}
for (j in 1:10) {
print(j)
dv <- drug_var[j]
drugs <- screening[[dv]]
for (i in 1:(nrow(screening))) {
tryCatch({
drug <- drugs[i]
if (!is.null(drug) && !(drug=='')) {
dc <- look_up_drug_class(drug)
if (length(dc) > 0) {
drug_class_not_found[i, j] <- F
drug_classes[[i]] <- c(drug_classes[[i]], dc)
} else {
drug_class_not_found[i, j] <- T
}
}
}, error=function(e) {
print(i)
print(j)
print(e)
})
}
}
library(dplyr)
library(tidyr)
library(haven)
library(ggplot2)
library(ggfortify)
library(knitr)
library(survival)
library(fuzzyjoin)
library(readr)
library(stringr)
library(httr)
library(jsonlite)
library(glmnet)
set.seed(32343)
2 + 3
c(1,2,3)
[1,2,3]
c(1,2,3)
c(a=1)
c(a=1, b=2)
library(dplyr)
library(tidyr)
library(haven)
library(ggplot2)
library(ggfortify)
library(knitr)
library(survival)
library(fuzzyjoin)
library(readr)
library(stringr)
library(httr)
library(jsonlite)
library(glmnet)
set.seed(32343)
screening_2 <- haven::read_sas(data_file = "data/dpp/Data/DPP_Data_2008/Form_Data/Data/s03.sas7bdat")
screening_3_start <- haven::read_sas(data_file = "data/dpp/Data/DPP_Data_2008/Form_Data/Data/s05.sas7bdat")
screening_3_end <- haven::read_sas(data_file = "data/dpp/Data/DPP_Data_2008/Form_Data/Data/s06.sas7bdat")
screening_3 <- full_join(screening_3_start, screening_3_end, by="RELEASE_ID")
screening_4 <- haven::read_sas(data_file = "data/dpp/Data/DPP_Data_2008/Form_Data/Data/s07.sas7bdat")
screening <- full_join(
full_join(screening_2, screening_3, by="RELEASE_ID"),
screening_4, by="RELEASE_ID")
baseline <- read_sas(data_file = "data/dpp/Data/DPP_Data_2008/Non-Form_Data/Data/basedata.sas7bdat")
lab <- read_sas(data_file = "data/dpp/Data/DPP_Data_2008/Non-Form_Data/Data/lab.sas7bdat")
lab <- lab %>% dplyr::filter(VISIT=="BAS") %>%
mutate(fasting_glucose=G000,
hdl=CHDL,
triglycerides=TRIG,
hba1c=HBA1) %>%
select(RELEASE_ID, fasting_glucose, hdl, triglycerides, hba1c)
standard_follow_up <- haven::read_sas(data_file = "data/dpp/Data/DPP_Data_2008/Form_Data/Data/f01.sas7bdat")
major_follow_up <- haven::read_sas(data_file = "data/dpp/Data/DPP_Data_2008/Form_Data/Data/f02.sas7bdat")
events <- haven::read_sas(data_file = "data/dpp/Data/DPP_Data_2008/Non-Form_Data/Data/events.sas7bdat")
rct_data <- inner_join(baseline, events, by="RELEASE_ID")
s <- survfit(Surv(time = DIABT, event = DIABF)~ASSIGN, data=rct_data %>% select(DIABF, DIABT, ASSIGN))
autoplot(s)
rct_data <- inner_join(baseline, events, by="RELEASE_ID")
s <- survfit(Surv(time = DIABT, event = 1-DIABF)~ASSIGN, data=rct_data %>% select(DIABF, DIABT, ASSIGN))
autoplot(s)
tmp_fn = Vectorize(function(s) {
attr(screening[[s]], "label")
})
var.descriptions <- as.data.frame(tmp_fn(names(screening)))
colnames(var.descriptions) <- c("Description")
kable(var.descriptions, format="markdown")
screening_features <- screening %>%
mutate(
waist_circumference=rowMeans(data.frame(SIWSTC1, SIWSTC2, SIWSTC3), na.rm = T),
hip_girth=rowMeans(data.frame(SIHIP1, SIHIP2, SIHIP3), na.rm = T)) %>%
mutate(waist_hip_ratio=waist_circumference / hip_girth) %>%
mutate(
family_hx_diabetes=!is.na(SIMDIAB==1 | SIFDIAB==1 | SISIBDI > 0),
family_hx_mi = !is.na(SIMMI == 1 | SIFMI == 1 | SISIBMI > 0),
smoked=SI100CG,
cursmoke=!is.na(SISMOK) & SISMOK==1,
weight_loss=SILSWGT,
weight_loss_ex = as.numeric(!is.na(SIWEXE == 1 | SIWFEXE == 1 | SIWCOMB == 1)),
weight_loss_diet = as.numeric(!is.na(SIWDIET == 1 | SIWCOMB==1)),
weight_loss_formal_program=as.numeric(!is.na(SIWFWL)),
weight_loss_meds=as.numeric(!is.na(SIWMED)),
living_arrangement=factor(SELVG),
educ=SEEDUC,
employment=factor(SEEMPL),
household_size=SEHOUSE,
income_unspecified=as.numeric(SEINC==8),
income=factor(ifelse(SEINC == 8, 0, SEINC)),
diet=as.numeric(!is.na(SISPECD) & (SISPECD == 1)),
periods=as.numeric(!is.na(SIMENS) & (SIMENS == 2 | SIMENS == 3)),
max_weight=SIMAXWT,
ethnicity=factor(ifelse(is.na(SOETHN), 7, SOETHN)),
#ethnicity=factor(SOETHN),
sbp=SOSBPA,
dbp=SODBPA,
urine_protein=SOPRTN,
taking_meds=SRRXDQ) %>%
select(RELEASE_ID,
waist_hip_ratio,
waist_circumference,
family_hx_diabetes,
family_hx_mi,
smoked,
cursmoke,
weight_loss,
weight_loss_ex ,
weight_loss_diet ,
weight_loss_formal_program,
weight_loss_meds,
living_arrangement,
educ,
employment,
household_size,
income_unspecified,
income,
diet,
periods,
max_weight,
ethnicity,
sbp,
dbp,
urine_protein,
taking_meds)
look_up_drug_class <- function(drug_name) {
request <- GET("https://rxnav.nlm.nih.gov/REST/rxclass/class/byDrugName.json", query = list(drugName=drug_name, relaSource="FDASPL"))
text_content <- content(request, "text", encoding = "UTF-8")
json_obj <- rjson::fromJSON(text_content)
drug_group <- Filter(function(dc) {
dc$rxclassMinConceptItem$classType == "EPC"
},
x=json_obj$rxclassDrugInfoList$rxclassDrugInfo)
classes <- lapply(drug_group, function(dc) {dc$rxclassMinConceptItem$classId})
return(classes)
}
drug_classes <- list()
drug_var <- c("SRRXDA1", "SRRXDB1", "SRRXDC1", "SRRXDD1", "SRRXDE1", "SRRXDF1", "SRRXDG1", "SRRXDH1", "SRRXDI1", "SRRXDJ1")
drug_class_not_found <- matrix(as.logical(rep(NA, 10*nrow(screening))), ncol=10)
for (i in 1:(nrow(screening))) {
drug_classes[[i]] <- list()
}
for (j in 1:10) {
print(j)
dv <- drug_var[j]
drugs <- screening[[dv]]
for (i in 1:(nrow(screening))) {
tryCatch({
drug <- drugs[i]
if (!is.null(drug) && !(drug=='')) {
dc <- look_up_drug_class(drug)
if (length(dc) > 0) {
drug_class_not_found[i, j] <- F
drug_classes[[i]] <- c(drug_classes[[i]], dc)
} else {
drug_class_not_found[i, j] <- T
}
}
}, error=function(e) {
print(i)
print(j)
print(e)
})
}
}
print(mean(drug_class_not_found, na.rm=T))
classes_frame <- data.frame(class_=as.vector(do.call(c, do.call(c, drug_classes))))
class_counts <- classes_frame %>% group_by(class_) %>% summarize(count=n()) %>% arrange(desc(count)) %>% mutate(index=1:n())
class_counts
ggplot(class_counts) + geom_point(aes(x=index, y=count))
for(class_ in (class_counts %>% dplyr::filter(count > 50))$class_) {
screening_features[[class_]] = unlist(lapply(drug_classes, function(dcs) {any(class_[1] %in% dcs)}))
}
look_up_drug_class <- function(drug_name) {
request <- GET("https://rxnav.nlm.nih.gov/REST/rxclass/class/byDrugName.json", query = list(drugName=drug_name, relaSource="FDASPL"))
text_content <- content(request, "text", encoding = "UTF-8")
json_obj <- rjson::fromJSON(text_content)
drug_group <- Filter(function(dc) {
dc$rxclassMinConceptItem$classType == "EPC"
},
x=json_obj$rxclassDrugInfoList$rxclassDrugInfo)
classes <- lapply(drug_group, function(dc) {dc$rxclassMinConceptItem$classId})
return(classes)
}
for(class_ in (class_counts %>% dplyr::fil
for(class_ in (class_counts %>% dplyr::fil
for(class_ in (class_counts %>% dplyr::filter(count > 50))$class_) {
screening_features[[class_]] = unlist(lapply(drug_classes, function(dcs) {any(class_[1] %in% dcs)}))
}
breslow.estimate <- function(time, event, links) {
tab <- data.frame(table(time[event==1]))
y <- as.numeric(levels(tab[, 1]))[tab[, 1]] #ordered distinct event times
d <- tab[, 2]                               #number of events
links <- links - mean(links)
h0 <- rep(NA, length(y))
for(l in 1:length(y))
{
h0[l] <- d[l] / sum(exp(links[time >= y[l]]))
}
H0 <- cumsum(h0)
S0 <- exp(-H0)
return(data.frame(time=y, hazard=H0, surv=S0))
}
censorship.rate <- function(outcome, study_time, X, t=10) {
outcome.times <- pmin(study_time, t+2)
censoring.var <- 1 - outcome
cm <- cv.glmnet(X, Surv(outcome.times+0.0001, censoring.var), family="cox")
print(coef(cm, s=min(cm$lambda)))
links <- predict(cm, newx=X, s=min(cm$lambda), type="link")
sf <- breslow.estimate(outcome.times+0.0001, censoring.var, links)
sf <- data.frame(time=c(-1, sf$time), survival=c(1.0, sf$surv))
hazard.ratio <- predict(cm, newx=X, type="response", s=min(cm$lambda))
mlhr = exp(mean(log(hazard.ratio)))
hazard.ratio <- hazard.ratio / mlhr
survival <- vapply(pmin(outcome.times, t),
function(u) {min(sf$surv[sf$time<=u])},
1)
survival <- survival ^ hazard.ratio
outcome.probs <- survival
return(outcome.probs)
}
data <- inner_join(inner_join(screening_features, events, by="RELEASE_ID"),
inner_join(baseline, lab, by="RELEASE_ID"),
by="RELEASE_ID") %>%
dplyr::filter(ASSIGN == "Metformin" | ASSIGN == "Lifestyle") %>%
dplyr::mutate(W = as.integer(ASSIGN == "Metformin"),
Y = DIABF,
T = DIABT) %>%
dplyr::select(-c(DEATH, DEATHDAYS, RELEASE_ID, DIABF, DIABT, DIABV,
FASTHYPV, FASTHYPT, TOTALTIM, RAND_PER, RACE_ETH,
ASSIGN)) %>%
na.omit
time_point <- 3.7
outcome <- (data$T <= time_point) & data$Y
keep <- outcome | (data$T >= time_point)
sprintf("Rows: %.2f   Columns: %.2f", dim(data)[1], dim(data)[2])
options(na.action='na.pass')
X <- model.matrix(
~living_arrangement+
educ+
employment+
household_size+
income_unspecified+
income +
W,
data=data)
censorship_prob <- censorship.rate(data$Y, data$T, X, t=time_point)
weights <- 1/censorship_prob
weights
censorship_prob
hist(censorship_prob)
hist(censorship_prob, breaks = 40)
weights
max(weights)
hist(weights)
weights
breslow.estimate <- function(time, event, links) {
tab <- data.frame(table(time[event==1]))
y <- as.numeric(levels(tab[, 1]))[tab[, 1]] #ordered distinct event times
d <- tab[, 2]                               #number of events
links <- links - mean(links)
h0 <- rep(NA, length(y))
for(l in 1:length(y))
{
h0[l] <- d[l] / sum(exp(links[time >= y[l]]))
}
H0 <- cumsum(h0)
S0 <- exp(-H0)
return(data.frame(time=y, hazard=H0, surv=S0))
}
tab <- data.frame(table(time[event==1]))
?brewslow.estimate
outcome = data$Y
study_time = data$T
X = X
t = time_point
outcome.times <- pmin(study_time, t+2)
outcome.times
study_time
t
t + 2
max(outcome.times)
censoring.var <- 1 - outcome
cm <- cv.glmnet(X, Surv(outcome.times+0.0001, censoring.var), family="cox")
print(coef(cm, s=min(cm$lambda)))
links <- predict(cm, newx=X, s=min(cm$lambda), type="link")
sf <- breslow.estimate(outcome.times+0.0001, censoring.var, links)
sf <- data.frame(time=c(-1, sf$time), survival=c(1.0, sf$surv))
hazard.ratio <- predict(cm, newx=X, type="response", s=min(cm$lambda))
outcome.times
breslow.estimate
sf
dim(sf)
sf <- breslow.estimate(outcome.times+0.0001, censoring.var, links)
dim(sf)
outcome.times <- pmin(study_time, t+2)
censoring.var <- 1 - outcome
cm <- cv.glmnet(X, Surv(outcome.times+0.0001, censoring.var), family="cox")
cm <- cv.glmnet(X, Surv(outcome.times+0.0001, censoring.var), family="cox")
print(coef(cm, s=min(cm$lambda)))
links <- predict(cm, newx=X, s=min(cm$lambda), type="link")
sf <- breslow.estimate(outcome.times+0.0001, censoring.var, links)
dim(sf)
sf
sf
sf$time
as_tibble(sf)
sf$time
sf$time
as_tibble(sf)
links
dim(links)
sf <- breslow.estimate(outcome.times+0.0001, censoring.var, links)
sf <- data.frame(time=c(-1, sf$time), survival=c(1.0, sf$surv))
hazard.ratio <- predict(cm, newx=X, type="response", s=min(cm$lambda))
mlhr = exp(mean(log(hazard.ratio)))
hazard.ratio <- hazard.ratio / mlhr
?vapply
?vapply
survival <- vapply(pmin(outcome.times, t),
function(u) {min(sf$surv[sf$time<=u])},
1)
survival
?coxph
library(survival)
?coxPH
?coxph
setwd("~/Projects/predicting-poverty/src/sampling")
library(tidyverse)
library(haven)
survey_data = read_stata("../data/pc0111_village_elec_road_dist_ag.dta")
survey_data
survey_data = read_stata("../data/pc0111_village_elec_road_dist_ag.dta")
survey_data
head(survey_data)
survey_data
survey_data$pc01_vd_power_all
survey_data
survey_data = survey_data %>%
mutate(village_id = pc11_village_id,
electrification = pc11_vd_power_all,
paved_road = pc11_vd_rd_p_btr,
distance_to_city = pc11_dist_km_town_pop100,
share_ag = secc_nco2d_cultiv_share) %>%
select(village_id, electrification, paved_road, distance_to_city, share_ag)
survey_data
india_data = read_csv("../data/india.csv")
india_data
survey_data$village_id
int(survey_data$village_id)
as.int(survey_data$village_id)
as.integer(survey_data$village_id)
survey_data$electrification
as.integer(survey_data$electrification)
as.integer(survey_data$paved_road)
as.integer(survey_data$distance_to_city)
as.integer(survey_data$share_ag)
as.float(survey_data$share_ag)
as.numeric(survey_data$share_ag)
as.logical(survey_data$electrification)
survey_data$distance_to_city
survey_data = read_stata("../data/pc0111_village_elec_road_dist_ag.dta")
survey_data = survey_data %>%
mutate(village_id = as.integer(pc11_village_id),
electrification = as.integer(pc11_vd_power_all),
paved_road = as.integer(pc11_vd_rd_p_btr),
distance_to_city = as.numeric(pc11_dist_km_town_pop100),
share_ag = as.numeric(secc_nco2d_cultiv_share)) %>%
select(village_id, electrification, paved_road, distance_to_city, share_ag)
survey_data
cor(survey_data$electrification, survey_data$paved_road)
complete = survey_data %>% na.omit
complete
cor(complete$electrification, complete$paved_road)
cor(complete$electrification, complete$share_ag)
cor(complete$electrification, complete$distance_to_city)
india_data
survey_data$village_id
print(paste("Initial survey dataset had", nrows(survey_data), "rows."))
print(paste("Initial survey dataset had", nrow(survey_data), "rows."))
india_data
india_data$id
india_data$id
print(paste("Initial survey dataset had", nrow(india), "rows."))
print(paste("Initial survey dataset had", nrow(india_data), "rows."))
survey_data$village_id
set(survey_data$village_id)
unique(survey_data$village_id)
length(unique(survey_data$village_id))
length(unique(india_data$id))
nrow(survey_data)
stopifnot(nrow(survey_data) == length(unique(survey_data$village_id)))
stopifnot(nrow(survey_data) == length(unique(survey_data$village_id)))
stopifnot(nrow(india_data) == length(unique(india_data$id)))
print(paste("Initial survey dataset had", nrow(survey_data), "rows,",
"and", length(unique(survey_data$village_id)), " unique ids."))
print(paste("Initial survey dataset had", nrow(survey_data), "rows,",
"and", length(unique(survey_data$village_id)), "unique ids."))
print(paste("Initial survey dataset had", nrow(india_data), "rows,",
"and", length(unique(india_data$id)), "unique ids."))
inner_join(survey_data, india_data)
inner_join(survey_data, india_data, by = c(village_id = id))
inner_join(survey_data, india_data, by = c("village_id" = "id"))
join_data = inner_join(survey_data, india_data, by = c("village_id" = "id"))
join_data
join_data$electrification
join_data = inner_join(survey_data, india_data, by = c("village_id" = "id"))
join_data$electrification
join_data$secc_cons_per_cap_scaled
complete = join_data %>% na.omit
cor(join_data$secc_cons_per_cap_scaled, join_data$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$paved_road)
cor(complete$secc_cons_per_cap_scaled, complete$distance_to_city)
cor(complete$secc_cons_per_cap_scaled, complete$share_ag)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification) ** 2
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap, complete$electrification)
cor(complete$secc_cons_per_hh, complete$electrification)
cor(complete$secc_cons, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
complete
library(tidyverse)
library(haven)
complete
print(paste("Joined dataset had", nrow(complete), "rows."))
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
print(paste("Joined dataset had", nrow(join_data), "rows."))
print(paste("Complete dataset had", nrow(complete), "rows."))
}
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$paved_road)
cor(complete$secc_cons_per_cap_scaled, complete$electrification)
cor(complete$secc_cons_per_cap_scaled, complete$paved_road)
cor(complete$secc_cons_per_cap_scaled, complete$distance_to_city)
cor(complete$secc_cons_per_cap_scaled, complete$share_ag)
c(a=cor(complete$secc_cons_per_cap_scaled, complete$electrification))
c(elec=cor(complete$secc_cons_per_cap_scaled, complete$electrification),
paved=cor(complete$secc_cons_per_cap_scaled, complete$paved_road),
dist=cor(complete$secc_cons_per_cap_scaled, complete$distance_to_city),
ag=cor(complete$secc_cons_per_cap_scaled, complete$share_ag))
print(cors)
print(paste("Initial survey dataset had", nrow(survey_data), "rows,",
"and", length(unique(survey_data$village_id)), "unique ids."))
india_data = read_csv("../data/india.csv")
print(paste("Initial survey dataset had", nrow(india_data), "rows,",
"and", length(unique(india_data$id)), "unique ids."))
join_data = inner_join(survey_data, india_data, by = c("village_id" = "id"))
complete = join_data %>% na.omit
print(paste("Joined dataset had", nrow(join_data), "rows."))
print(paste("Complete dataset had", nrow(complete), "rows."))
cors = c(elec=cor(complete$secc_cons_per_cap_scaled, complete$electrification),
paved=cor(complete$secc_cons_per_cap_scaled, complete$paved_road),
dist=cor(complete$secc_cons_per_cap_scaled, complete$distance_to_city),
ag=cor(complete$secc_cons_per_cap_scaled, complete$share_ag))
print(cors)
print("-- Correlations")
print(cors)
